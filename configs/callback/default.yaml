model_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${hydra:run.dir}/checkpoints
  filename: best
  monitor: train/loss
  mode: min
  save_last: True
  save_top_k: 3
  every_n_epochs: 1

early_stopping:
  _target_: pytorch_lightning.callbacks.EarlyStopping
  monitor: train/loss
  mode: min
  patience: 100

learning_ratemonitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: epoch